# Daily training workflow â€” retrain/evaluate and register model
# - Skip Git LFS checkout to avoid LFS quota failures
# - Pin numpy and scikit-learn to avoid ABI mismatches with compiled wheels
on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 02:00 UTC
  workflow_dispatch:

concurrency:
  group: daily-train
  cancel-in-progress: true

jobs:
  train:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository (skip LFS fetch to avoid quota errors)
        uses: actions/checkout@v4
        with:
          lfs: false
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Cache pip (include numpy & sklearn versions in key)
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}-numpy-1.26.4-sklearn-1.2.2
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies (pin numpy then sklearn)
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip setuptools wheel
          # 1) Pin numpy first to prevent pip from upgrading to incompatible numpy>=2.x
          python -m pip install --no-cache-dir --prefer-binary "numpy==1.26.4"
          # 2) Install other requirements without numpy / scikit-learn
          if [ -f requirements.txt ]; then
            sed '/^[[:space:]]*numpy/Id; /^[[:space:]]*scikit-learn/Id' requirements.txt > /tmp/reqs_no_np_skl.txt || true
            pip install --no-cache-dir -r /tmp/reqs_no_np_skl.txt || true
          fi
          # 3) Install the exact scikit-learn you use locally
          python -m pip install --no-cache-dir --prefer-binary "scikit-learn==1.2.2"
        shell: bash

      - name: Verify Python / numpy / pandas / sklearn (sanity check)
        run: |
          python - <<'PY'
          import sys, importlib
          print("python", sys.version.splitlines()[0])
          for n in ("numpy", "pandas", "sklearn"):
              try:
                  m = importlib.import_module(n)
                  print(n, m.__version__)
              except Exception as e:
                  print(n, "import error:", e)
          PY
        shell: bash

      - name: Prepare .env from secrets (sanitized)
        env:
          HOPSWORKS_HOST_RAW: ${{ secrets.HOPSWORKS_HOST }}
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          HOPSWORKS_PROJECT_ID: ${{ secrets.HOPSWORKS_PROJECT_ID }}
          HOPSWORKS_FEATURE_GROUP: ${{ secrets.HOPSWORKS_FEATURE_GROUP }}
          HOPSWORKS_FEATURE_GROUP_VERSION: ${{ secrets.HOPSWORKS_FEATURE_GROUP_VERSION }}
          OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        run: |
          set -euo pipefail
          HOST_SANITIZED="$(printf '%s' "$HOPSWORKS_HOST_RAW" | sed -e 's~https\?://~~I' -e 's:/*$::')"
          : > .env
          printf "HOPSWORKS_HOST=%s\n" "$HOST_SANITIZED" >> .env
          printf "HOPSWORKS_API_KEY=%s\n" "$HOPSWORKS_API_KEY" >> .env
          printf "HOPSWORKS_PROJECT_ID=%s\n" "$HOPSWORKS_PROJECT_ID" >> .env
          printf "HOPSWORKS_FEATURE_GROUP=%s\n" "$HOPSWORKS_FEATURE_GROUP" >> .env
          printf "HOPSWORKS_FEATURE_GROUP_VERSION=%s\n" "$HOPSWORKS_FEATURE_GROUP_VERSION" >> .env
          printf "OPENWEATHER_API_KEY=%s\n" "$OPENWEATHER_API_KEY" >> .env
          # show redacted preview for debugging (no secret values printed)
          echo ".env preview (keys only):"
          sed -n '1,200p' .env | sed -e 's/=.*/=<REDACTED>/g'
        shell: bash

      - name: Optional - HOPSWORKS secrets presence check (no network)
        env:
          HOPSWORKS_HOST_RAW: ${{ secrets.HOPSWORKS_HOST }}
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        run: |
          set -euo pipefail
          echo "HOPSWORKS_HOST set: ${HOPSWORKS_HOST_RAW:+yes}"
          echo "HOPSWORKS_API_KEY present: ${HOPSWORKS_API_KEY:+yes}"
          echo "OPENWEATHER_API_KEY present: ${OPENWEATHER_API_KEY:+yes}"
        shell: bash
        continue-on-error: true

      - name: Run training (with Hopsworks secrets in env)
        id: train
        env:
          HOPSWORKS_HOST: ${{ secrets.HOPSWORKS_HOST }}
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
          HOPSWORKS_PROJECT_ID: ${{ secrets.HOPSWORKS_PROJECT_ID }}
          HOPSWORKS_FEATURE_GROUP: ${{ secrets.HOPSWORKS_FEATURE_GROUP }}
          HOPSWORKS_FEATURE_GROUP_VERSION: ${{ secrets.HOPSWORKS_FEATURE_GROUP_VERSION }}
          OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
        run: |
          set -euo pipefail
          mkdir -p logs artifacts models
          echo "HOPSWORKS_HOST present: ${HOPSWORKS_HOST:+yes}"
          echo "HOPSWORKS_API_KEY present: ${HOPSWORKS_API_KEY:+yes}"
          if [ -f "train.py" ]; then
            python train.py 2>&1 | tee logs/train.log
          elif [ -f "src/train.py" ]; then
            python src/train.py 2>&1 | tee logs/train.log
          else
            echo "ERROR: train.py not found; aborting."
            ls -R .
            exit 2
          fi
        shell: bash

      - name: Upload training logs & artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: daily-train-artifacts
          path: |
            logs
            artifacts
            models

      - name: Post Cache pip
        if: always()
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}-numpy-1.26.4-sklearn-1.2.2
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Debug - confirm features/history timestamps
        run: |
          python << 'EOF'
          from datetime import datetime, timezone
          import os, pandas as pd
          print('now_utc:', datetime.now(timezone.utc))
          for p in ('features_with_standard_aqi.csv', 'features_preprocessed.csv', 'history.csv'):
              if os.path.exists(p):
                  try:
                      df = pd.read_csv(p, parse_dates=['time'])
                      df['time'] = pd.to_datetime(df['time'], utc=True)
                      print(f"{p}: rows={len(df)} first={df['time'].min()} last={df['time'].max()}")
                      print(df.tail(3).to_string(index=False))
                  except Exception as e:
                      print('Failed to read', p, ':', e)
              else:
                  print('Missing:', p)
          EOF
        shell: bash
