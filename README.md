# Karachi_10Pearl_aqi

# Karachi Air Quality Forecast (Streamlit)

A Streamlit dashboard and MLOps pipeline for hourly Air Quality Index (AQI) forecasting in Karachi. The system uses OpenWeather hourly data, Hopsworks Feature Store and Model Registry, and GitHub Actions for automated ingestion and daily retraining. The dashboard shows live current AQI and a 72-hour forecast generated by an in-process predictor.

This README includes:
- Project overview and scope
- Data sources, preprocessing and feature engineering
- Exploratory Data Analysis (EDA) checklist and sample checks to reproduce
- Model training, evaluation and prediction pipeline (recursive forecasting)
- CI/CD automation and deployment notes
- Dashboard usage and configuration
- Developer notes and next steps

---

## 1. Project Overview

This system predicts the Air Quality Index (AQI) for Karachi’s Pearl regions using an automated MLOps pipeline built with Python, Hopsworks Feature Store, and GitHub Actions. It:
- Automatically fetches hourly OpenWeather data for 12 months
- Preprocesses and engineers features (77 features derived from 10 raw ones)
- Trains ML models daily and stores artifacts in Hopsworks Model Registry
- Runs an in-process predictor to produce a 72-hour AQI forecast shown in a Streamlit dashboard

The pipeline supports hourly ingestion and daily retraining to keep forecasts up-to-date.

---

## 2. Data & Preprocessing

### a) Data Sources
- Source: OpenWeather API (hourly data, 12 months)
- Raw features (10): temperature, humidity, wind speed, pressure, PM2.5, PM10, NO₂, O₃, CO, visibility
- Timestamps & time features: hour, day, month, year, weekday

Because OpenWeather does not provide US EPA AQI directly, the standard AQI is computed using the standard linear interpolation formula:
(I_hi − I_lo)/(C_hi − C_lo) × (C − C_lo) + I_lo
where C is the pollutant concentration and the breakpoints correspond to EPA tables.

### b) Feature Engineering
From the 10 raw variables a total of ~77 features were generated and stored in Hopsworks. High-level categories:

- Raw (10): temperature, humidity, PM2.5, ...
- Time-based (≈10): hour, weekday, hour_sin, month_cos, etc.
- Lag features (≈20): standard_aqi_lag_1, lag_6, lag_72, etc.
- Rolling statistics (≈15): roll_mean_6h, roll_std_24h, roll_max_24h.
- Change rates (≈10): AQI diff, pct_change.
- Interaction (≈5): temp×humidity, pm_ratio, oxidant_sum.
- Targets (3): next_1h, next_24h, next_72h (the model trained for next_24h).

This set captures short-term dynamics and seasonal patterns.

### c) Missing Data Handling
- Sequence: forward-fill → backward-fill for short gaps; median fill for numeric columns; "Unknown" for categorical.
- To prevent leakage: direct future targets columns (e.g., standard_aqi_next_1h, etc.) are excluded from training inputs.
- The model is trained on `standard_aqi_next_24h` as the main target.

---

## 3. Historical Backfill & Feature Store

A backfill pipeline reconstructs one year of hourly history:
- Fetch hourly OpenWeather data
- Compute AQI and engineered features
- Preprocess, apply imputation and leak prevention
- Save to `features_preprocessed.csv` and upload to Hopsworks Feature Store
- Each row represents 1 hour with the full feature set and target(s)

This ensures reproducibility and consistent features for training and live prediction.

---

## 4. Exploratory Data Analysis (EDA) — Checklist & Reproducible Checks

The EDA should verify data quality, distributions, trends, correlations and stationarity. Below is a checklist and sample code snippets to reproduce key checks.

EDA Checklist
- [ ] Data completeness: check missingness per column over time
- [ ] Value ranges: verify pollutant ranges and outliers
- [ ] Time coverage: confirm hourly continuity for the year
- [ ] Seasonality & trends: daily, weekly patterns in PM2.5/PM10 and AQI
- [ ] Autocorrelation: ACF/PACF for AQI to justify lag features
- [ ] Correlations: Pearson/Spearman among variables and between features and target
- [ ] Stationarity tests: Augmented Dickey-Fuller for key series
- [ ] Feature importance baseline: simple RF feature importances for sanity

Reproducible checks (examples)
- Missingness summary:
```python
import pandas as pd
df = pd.read_csv("features_preprocessed.csv", parse_dates=["time"])
missing = df.isna().mean().sort_values(ascending=False)
print(missing.head(20))
```

- Hourly coverage:
```python
time_idx = pd.to_datetime(df["time"])
gap = time_idx.diff().dt.total_seconds().div(3600).value_counts().sort_index()
print(gap.head(10))
```

- Distribution of PM2.5 & PM10:
```python
import seaborn as sns, matplotlib.pyplot as plt
sns.histplot(df["pm2_5"].dropna(), bins=80, kde=True)
plt.title("pm2_5 distribution (one-year)")
plt.show()
```

- Daily seasonality:
```python
daily = df.set_index("time").resample("D")["standard_aqi"].mean()
daily.plot(title="Daily mean AQI (one-year)")
```

- ACF / PACF:
```python
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plot_acf(df["standard_aqi"].dropna().values, lags=72)
plot_pacf(df["standard_aqi"].dropna().values, lags=72)
```

- Feature correlation heatmap (top features):
```python
corr = df.select_dtypes(include="number").corr()
sns.heatmap(corr.loc["standard_aqi"].abs().sort_values(ascending=False).head(30).to_frame(), annot=True)
```

EDA Report
- Add plots and tables into `reports/eda_report.ipynb` or `reports/eda_report.html` to archive findings.
- Note any systemic measurement gaps, sensor anomalies, or seasonal events (dust storms etc.) for downstream model considerations.

---

## 5. Model Training & Evaluation

- Training split: 80/20 train-test on time-ordered data
- Models trained and compared: Random Forest (deployed), XGBoost, LightGBM, SARIMAX
- Metrics recorded (example):

| Model         | Train R² | Test R² | MAE   | RMSE   |
|---------------|----------|---------|-------|--------|
| Random Forest | 0.9320   | 0.7000  | 17.63 | 21.76  |
| XGBoost       | 0.9959   | 0.5695  | 21.26 | 26.07  |
| LightGBM      | 0.9884   | 0.5938  | 21.01 | 25.32  |
| SARIMAX       | 0.9594   | -3.067  | 57.68 | 80.13  |

- Insights: Random Forest generalized best; XGBoost/LightGBM show overfitting; SARIMAX fails on 1-year series.
- Deployed model: Random Forest with hyperparameter tuning; artifacts saved in Hopsworks Model Registry.

---

## 6. Prediction Pipeline (Recursive Forecasting)

`predict.py` performs recursive forecasting for the next 72 hours:
1. Load model, scaler, medians and feature list (from Hopsworks or local backup)
2. Fetch last 48 hours of features
3. Create 72 future timestamps and iteratively predict:
```py
for i in range(72):
    sub = combined.iloc[:hist_rows + i + 1]
    eng = engineer_features(sub, return_last_row=True)
    pred = model.predict(scaler.transform(X_row))
    combined.at[hist_rows + i, "standard_aqi"] = pred
```
- Predictions are saved to `predictions.csv`.
- Performance: Best up to 6–24h; reasonably stable to 72h with increasing uncertainty/drift.

---

## 7. Automation & CI/CD

Two GitHub Actions workflows drive automation:
- `hourly_ingest_pip.yml` — hourly ingestion + feature update to Hopsworks
- `train_daily.yml` — daily model retrain at 02:00 UTC, uploads artifacts to Hopsworks and GitHub artifacts

Workflow steps:
- Set up Python 3.12.7
- Install dependencies (requirements.txt)
- Load secrets (.env)
- Run ingestion or training scripts
- Upload logs & artifacts

This ensures continuous refresh of the model and feature store.

---

## 8. Dashboard & Visualization

- App file: `streamlit_app.py` (or `app.py`)
- Displays:
  - Current AQI (Live from OpenWeather when configured)
  - Forecast table (next 72 hours)
  - Forecast charts and pollutant forecasts (pm2_5/pm10) — pollutant forecasts shown only if predictor provides them; otherwise a synthetic fallback may be used for demo
  - SHAP-based interpretability (optional; heavy)
- Notes:
  - To show pollutant forecasts, update predictor to return pm2_5/pm10 in `get_predictions_for_dashboard`.
  - The app warns when Hopsworks reads time out and uses synthetic fallback data.

Start dashboard:
```bash
streamlit run streamlit_app.py
```
Open http://localhost:8501

---

## 9. EDA & Model Checkpointing — Reproducible Commands

- Run EDA notebook:
```bash
jupyter nbconvert --to html reports/eda_report.ipynb
# or open interactively
jupyter notebook reports/eda_report.ipynb
```

- Run training locally (example):
```bash
python train.py --config configs/train_config.yaml
```

- Produce predictions locally for testing:
```bash
python predict.py --horizon 72 --output predictions.csv
```

---

## 10. Technologies & Libraries

- Python, Pandas, NumPy
- Scikit-learn, XGBoost, LightGBM, statsmodels (SARIMAX)
- Hopsworks Feature Store & Model Registry
- GitHub Actions for CI / CD
- Streamlit dashboard (Plotly / Matplotlib fallback)
- SHAP for model explanations (optional)

---

## 11. Developer Notes & Next Steps

- To plot pollutant forecasts (pm2_5/pm10), update `predict.get_predictions_for_dashboard` to return pollutant forecasts and include them in `forecast_df`.
- Consider precomputing SHAP summaries offline and storing them as artifacts to avoid heavy compute in the live dashboard.
- Increase Hopsworks read timeout or add retry/backoff if you experience transient timeouts.
- Optionally remove synthetic fallbacks in production so charts are blank if live data is unavailable.

---

## 12. Contact & Attribution

Maintainer: `humaila0`  
This repository and report were prepared as part of the Karachi Air Quality Forecasting System.

---

## Appendix: Project Report (concise)
### Air Quality Forecasting System – Project Report
1. Project overview: automated pipeline for hourly AQI forecasting using OpenWeather → Hopsworks → training → Streamlit dashboard.
2. Data & preprocessing: 10 raw features → 77 engineered features. AQI computed from pollutant concentrations using standard EPA breakpoints.
3. Historical backfill: reconstructs one year of hourly features and uploads to Hopsworks.
4. Model training & evaluation: Random Forest selected as deployed model (best generalization); other baselines include XGBoost, LightGBM, SARIMAX.
5. Prediction pipeline: recursive forecasting for 72h, iterative use of predicted values as inputs for next steps.
6. Automation: GitHub Actions for hourly ingestion and daily training.
7. Dashboard: Streamlit visualization for live current AQI and 72h forecasts; includes warnings for hazardous AQI > 200.
8. Technologies: Python ecosystem, Hopsworks, GitHub Actions, Streamlit.
9. Summary: end-to-end pipeline with daily retrain and hourly predictions; Random Forest deployed for robust next-24h forecasts.
